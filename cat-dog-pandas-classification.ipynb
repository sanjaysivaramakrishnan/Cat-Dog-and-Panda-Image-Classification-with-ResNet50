{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13275007,"sourceType":"datasetVersion","datasetId":8412636}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### Load all dependencies","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import transforms, datasets, models\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision.datasets import ImageFolder\nfrom torchsummary import summary\nfrom PIL import Image\nfrom tqdm import tqdm    # for progress bar\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-17T12:49:02.614956Z","iopub.execute_input":"2025-10-17T12:49:02.615305Z","iopub.status.idle":"2025-10-17T12:49:02.620767Z","shell.execute_reply.started":"2025-10-17T12:49:02.615280Z","shell.execute_reply":"2025-10-17T12:49:02.619949Z"}},"outputs":[],"execution_count":108},{"cell_type":"markdown","source":"#### Set device","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ntorch.manual_seed(42)\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T12:49:02.622041Z","iopub.execute_input":"2025-10-17T12:49:02.622361Z","iopub.status.idle":"2025-10-17T12:49:02.640943Z","shell.execute_reply.started":"2025-10-17T12:49:02.622335Z","shell.execute_reply":"2025-10-17T12:49:02.640198Z"}},"outputs":[{"execution_count":109,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":109},{"cell_type":"markdown","source":"#### Define Transform","metadata":{}},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Lambda(lambda img: img.convert('RGB')),\n    transforms.Resize((224, 224)),\n    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n\ntest_transform = transforms.Compose([\n    transforms.Lambda(lambda img: img.convert('RGB')),\n    transforms.Resize((224,254)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T12:49:02.641897Z","iopub.execute_input":"2025-10-17T12:49:02.642432Z","iopub.status.idle":"2025-10-17T12:49:02.654921Z","shell.execute_reply.started":"2025-10-17T12:49:02.642405Z","shell.execute_reply":"2025-10-17T12:49:02.654102Z"}},"outputs":[],"execution_count":110},{"cell_type":"markdown","source":"#### Load data","metadata":{}},{"cell_type":"code","source":"train_data = ImageFolder('/kaggle/input/cat-dog-pandas/Cat-Dog_Pandas/Train',\n                        transform = train_transform)\nval_data = ImageFolder('/kaggle/input/cat-dog-pandas/Cat-Dog_Pandas/Valid',\n                      transform = test_transform)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T12:49:02.655994Z","iopub.execute_input":"2025-10-17T12:49:02.656370Z","iopub.status.idle":"2025-10-17T12:49:05.485211Z","shell.execute_reply.started":"2025-10-17T12:49:02.656311Z","shell.execute_reply":"2025-10-17T12:49:05.484540Z"}},"outputs":[],"execution_count":111},{"cell_type":"code","source":"class_names = train_data.classes   # different classes in our datasets\nclass_names","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T12:49:05.487548Z","iopub.execute_input":"2025-10-17T12:49:05.488138Z","iopub.status.idle":"2025-10-17T12:49:05.493391Z","shell.execute_reply.started":"2025-10-17T12:49:05.488022Z","shell.execute_reply":"2025-10-17T12:49:05.492665Z"}},"outputs":[{"execution_count":112,"output_type":"execute_result","data":{"text/plain":"['cat', 'dog', 'panda']"},"metadata":{}}],"execution_count":112},{"cell_type":"markdown","source":"#### Data loader","metadata":{}},{"cell_type":"code","source":"train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T12:49:05.494236Z","iopub.execute_input":"2025-10-17T12:49:05.494484Z","iopub.status.idle":"2025-10-17T12:49:05.510513Z","shell.execute_reply.started":"2025-10-17T12:49:05.494466Z","shell.execute_reply":"2025-10-17T12:49:05.509709Z"}},"outputs":[],"execution_count":113},{"cell_type":"code","source":"dataiter = iter(train_loader)\nfeatures,label = next(dataiter)\nprint('number of data per batch: ',len(features))\nprint('number of label per batch: ',len(label))\nprint('labels : ',label.unique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T12:49:05.511341Z","iopub.execute_input":"2025-10-17T12:49:05.511596Z","iopub.status.idle":"2025-10-17T12:49:05.829158Z","shell.execute_reply.started":"2025-10-17T12:49:05.511577Z","shell.execute_reply":"2025-10-17T12:49:05.828244Z"}},"outputs":[{"name":"stdout","text":"number of data per batch:  32\nnumber of label per batch:  32\nlabels :  tensor([0, 1, 2])\n","output_type":"stream"}],"execution_count":114},{"cell_type":"markdown","source":"#### ResNet50 Tensfor Learning technique","metadata":{}},{"cell_type":"code","source":"model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n    \n# Unfreeze only deeper layers for fine-tuning\nfor name, param in model.named_parameters():\n    if \"layer4\" in name or \"fc\" in name:\n        param.requires_grad = True\n    else:\n        param.requires_grad = False\n\nnum_features = model.fc.in_features  \nmodel.fc = nn.Sequential(\n    nn.Linear(num_features, 512),\n    nn.ReLU(inplace=True),\n    nn.Dropout(0.6),\n    nn.Linear(512,128),\n    nn.ReLU(inplace=True),\n    nn.Dropout(0.3),\n    nn.Linear(128, 3)).to(device) # 3 classes dog, cat, pandas\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T12:49:05.830181Z","iopub.execute_input":"2025-10-17T12:49:05.830442Z","iopub.status.idle":"2025-10-17T12:49:06.335369Z","shell.execute_reply.started":"2025-10-17T12:49:05.830422Z","shell.execute_reply":"2025-10-17T12:49:06.334667Z"}},"outputs":[],"execution_count":115},{"cell_type":"code","source":"summary(model,input_size=(3,224,244))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T12:49:06.336158Z","iopub.execute_input":"2025-10-17T12:49:06.336425Z","iopub.status.idle":"2025-10-17T12:49:06.372125Z","shell.execute_reply.started":"2025-10-17T12:49:06.336407Z","shell.execute_reply":"2025-10-17T12:49:06.371401Z"}},"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 64, 112, 122]           9,408\n       BatchNorm2d-2         [-1, 64, 112, 122]             128\n              ReLU-3         [-1, 64, 112, 122]               0\n         MaxPool2d-4           [-1, 64, 56, 61]               0\n            Conv2d-5           [-1, 64, 56, 61]           4,096\n       BatchNorm2d-6           [-1, 64, 56, 61]             128\n              ReLU-7           [-1, 64, 56, 61]               0\n            Conv2d-8           [-1, 64, 56, 61]          36,864\n       BatchNorm2d-9           [-1, 64, 56, 61]             128\n             ReLU-10           [-1, 64, 56, 61]               0\n           Conv2d-11          [-1, 256, 56, 61]          16,384\n      BatchNorm2d-12          [-1, 256, 56, 61]             512\n           Conv2d-13          [-1, 256, 56, 61]          16,384\n      BatchNorm2d-14          [-1, 256, 56, 61]             512\n             ReLU-15          [-1, 256, 56, 61]               0\n       Bottleneck-16          [-1, 256, 56, 61]               0\n           Conv2d-17           [-1, 64, 56, 61]          16,384\n      BatchNorm2d-18           [-1, 64, 56, 61]             128\n             ReLU-19           [-1, 64, 56, 61]               0\n           Conv2d-20           [-1, 64, 56, 61]          36,864\n      BatchNorm2d-21           [-1, 64, 56, 61]             128\n             ReLU-22           [-1, 64, 56, 61]               0\n           Conv2d-23          [-1, 256, 56, 61]          16,384\n      BatchNorm2d-24          [-1, 256, 56, 61]             512\n             ReLU-25          [-1, 256, 56, 61]               0\n       Bottleneck-26          [-1, 256, 56, 61]               0\n           Conv2d-27           [-1, 64, 56, 61]          16,384\n      BatchNorm2d-28           [-1, 64, 56, 61]             128\n             ReLU-29           [-1, 64, 56, 61]               0\n           Conv2d-30           [-1, 64, 56, 61]          36,864\n      BatchNorm2d-31           [-1, 64, 56, 61]             128\n             ReLU-32           [-1, 64, 56, 61]               0\n           Conv2d-33          [-1, 256, 56, 61]          16,384\n      BatchNorm2d-34          [-1, 256, 56, 61]             512\n             ReLU-35          [-1, 256, 56, 61]               0\n       Bottleneck-36          [-1, 256, 56, 61]               0\n           Conv2d-37          [-1, 128, 56, 61]          32,768\n      BatchNorm2d-38          [-1, 128, 56, 61]             256\n             ReLU-39          [-1, 128, 56, 61]               0\n           Conv2d-40          [-1, 128, 28, 31]         147,456\n      BatchNorm2d-41          [-1, 128, 28, 31]             256\n             ReLU-42          [-1, 128, 28, 31]               0\n           Conv2d-43          [-1, 512, 28, 31]          65,536\n      BatchNorm2d-44          [-1, 512, 28, 31]           1,024\n           Conv2d-45          [-1, 512, 28, 31]         131,072\n      BatchNorm2d-46          [-1, 512, 28, 31]           1,024\n             ReLU-47          [-1, 512, 28, 31]               0\n       Bottleneck-48          [-1, 512, 28, 31]               0\n           Conv2d-49          [-1, 128, 28, 31]          65,536\n      BatchNorm2d-50          [-1, 128, 28, 31]             256\n             ReLU-51          [-1, 128, 28, 31]               0\n           Conv2d-52          [-1, 128, 28, 31]         147,456\n      BatchNorm2d-53          [-1, 128, 28, 31]             256\n             ReLU-54          [-1, 128, 28, 31]               0\n           Conv2d-55          [-1, 512, 28, 31]          65,536\n      BatchNorm2d-56          [-1, 512, 28, 31]           1,024\n             ReLU-57          [-1, 512, 28, 31]               0\n       Bottleneck-58          [-1, 512, 28, 31]               0\n           Conv2d-59          [-1, 128, 28, 31]          65,536\n      BatchNorm2d-60          [-1, 128, 28, 31]             256\n             ReLU-61          [-1, 128, 28, 31]               0\n           Conv2d-62          [-1, 128, 28, 31]         147,456\n      BatchNorm2d-63          [-1, 128, 28, 31]             256\n             ReLU-64          [-1, 128, 28, 31]               0\n           Conv2d-65          [-1, 512, 28, 31]          65,536\n      BatchNorm2d-66          [-1, 512, 28, 31]           1,024\n             ReLU-67          [-1, 512, 28, 31]               0\n       Bottleneck-68          [-1, 512, 28, 31]               0\n           Conv2d-69          [-1, 128, 28, 31]          65,536\n      BatchNorm2d-70          [-1, 128, 28, 31]             256\n             ReLU-71          [-1, 128, 28, 31]               0\n           Conv2d-72          [-1, 128, 28, 31]         147,456\n      BatchNorm2d-73          [-1, 128, 28, 31]             256\n             ReLU-74          [-1, 128, 28, 31]               0\n           Conv2d-75          [-1, 512, 28, 31]          65,536\n      BatchNorm2d-76          [-1, 512, 28, 31]           1,024\n             ReLU-77          [-1, 512, 28, 31]               0\n       Bottleneck-78          [-1, 512, 28, 31]               0\n           Conv2d-79          [-1, 256, 28, 31]         131,072\n      BatchNorm2d-80          [-1, 256, 28, 31]             512\n             ReLU-81          [-1, 256, 28, 31]               0\n           Conv2d-82          [-1, 256, 14, 16]         589,824\n      BatchNorm2d-83          [-1, 256, 14, 16]             512\n             ReLU-84          [-1, 256, 14, 16]               0\n           Conv2d-85         [-1, 1024, 14, 16]         262,144\n      BatchNorm2d-86         [-1, 1024, 14, 16]           2,048\n           Conv2d-87         [-1, 1024, 14, 16]         524,288\n      BatchNorm2d-88         [-1, 1024, 14, 16]           2,048\n             ReLU-89         [-1, 1024, 14, 16]               0\n       Bottleneck-90         [-1, 1024, 14, 16]               0\n           Conv2d-91          [-1, 256, 14, 16]         262,144\n      BatchNorm2d-92          [-1, 256, 14, 16]             512\n             ReLU-93          [-1, 256, 14, 16]               0\n           Conv2d-94          [-1, 256, 14, 16]         589,824\n      BatchNorm2d-95          [-1, 256, 14, 16]             512\n             ReLU-96          [-1, 256, 14, 16]               0\n           Conv2d-97         [-1, 1024, 14, 16]         262,144\n      BatchNorm2d-98         [-1, 1024, 14, 16]           2,048\n             ReLU-99         [-1, 1024, 14, 16]               0\n      Bottleneck-100         [-1, 1024, 14, 16]               0\n          Conv2d-101          [-1, 256, 14, 16]         262,144\n     BatchNorm2d-102          [-1, 256, 14, 16]             512\n            ReLU-103          [-1, 256, 14, 16]               0\n          Conv2d-104          [-1, 256, 14, 16]         589,824\n     BatchNorm2d-105          [-1, 256, 14, 16]             512\n            ReLU-106          [-1, 256, 14, 16]               0\n          Conv2d-107         [-1, 1024, 14, 16]         262,144\n     BatchNorm2d-108         [-1, 1024, 14, 16]           2,048\n            ReLU-109         [-1, 1024, 14, 16]               0\n      Bottleneck-110         [-1, 1024, 14, 16]               0\n          Conv2d-111          [-1, 256, 14, 16]         262,144\n     BatchNorm2d-112          [-1, 256, 14, 16]             512\n            ReLU-113          [-1, 256, 14, 16]               0\n          Conv2d-114          [-1, 256, 14, 16]         589,824\n     BatchNorm2d-115          [-1, 256, 14, 16]             512\n            ReLU-116          [-1, 256, 14, 16]               0\n          Conv2d-117         [-1, 1024, 14, 16]         262,144\n     BatchNorm2d-118         [-1, 1024, 14, 16]           2,048\n            ReLU-119         [-1, 1024, 14, 16]               0\n      Bottleneck-120         [-1, 1024, 14, 16]               0\n          Conv2d-121          [-1, 256, 14, 16]         262,144\n     BatchNorm2d-122          [-1, 256, 14, 16]             512\n            ReLU-123          [-1, 256, 14, 16]               0\n          Conv2d-124          [-1, 256, 14, 16]         589,824\n     BatchNorm2d-125          [-1, 256, 14, 16]             512\n            ReLU-126          [-1, 256, 14, 16]               0\n          Conv2d-127         [-1, 1024, 14, 16]         262,144\n     BatchNorm2d-128         [-1, 1024, 14, 16]           2,048\n            ReLU-129         [-1, 1024, 14, 16]               0\n      Bottleneck-130         [-1, 1024, 14, 16]               0\n          Conv2d-131          [-1, 256, 14, 16]         262,144\n     BatchNorm2d-132          [-1, 256, 14, 16]             512\n            ReLU-133          [-1, 256, 14, 16]               0\n          Conv2d-134          [-1, 256, 14, 16]         589,824\n     BatchNorm2d-135          [-1, 256, 14, 16]             512\n            ReLU-136          [-1, 256, 14, 16]               0\n          Conv2d-137         [-1, 1024, 14, 16]         262,144\n     BatchNorm2d-138         [-1, 1024, 14, 16]           2,048\n            ReLU-139         [-1, 1024, 14, 16]               0\n      Bottleneck-140         [-1, 1024, 14, 16]               0\n          Conv2d-141          [-1, 512, 14, 16]         524,288\n     BatchNorm2d-142          [-1, 512, 14, 16]           1,024\n            ReLU-143          [-1, 512, 14, 16]               0\n          Conv2d-144            [-1, 512, 7, 8]       2,359,296\n     BatchNorm2d-145            [-1, 512, 7, 8]           1,024\n            ReLU-146            [-1, 512, 7, 8]               0\n          Conv2d-147           [-1, 2048, 7, 8]       1,048,576\n     BatchNorm2d-148           [-1, 2048, 7, 8]           4,096\n          Conv2d-149           [-1, 2048, 7, 8]       2,097,152\n     BatchNorm2d-150           [-1, 2048, 7, 8]           4,096\n            ReLU-151           [-1, 2048, 7, 8]               0\n      Bottleneck-152           [-1, 2048, 7, 8]               0\n          Conv2d-153            [-1, 512, 7, 8]       1,048,576\n     BatchNorm2d-154            [-1, 512, 7, 8]           1,024\n            ReLU-155            [-1, 512, 7, 8]               0\n          Conv2d-156            [-1, 512, 7, 8]       2,359,296\n     BatchNorm2d-157            [-1, 512, 7, 8]           1,024\n            ReLU-158            [-1, 512, 7, 8]               0\n          Conv2d-159           [-1, 2048, 7, 8]       1,048,576\n     BatchNorm2d-160           [-1, 2048, 7, 8]           4,096\n            ReLU-161           [-1, 2048, 7, 8]               0\n      Bottleneck-162           [-1, 2048, 7, 8]               0\n          Conv2d-163            [-1, 512, 7, 8]       1,048,576\n     BatchNorm2d-164            [-1, 512, 7, 8]           1,024\n            ReLU-165            [-1, 512, 7, 8]               0\n          Conv2d-166            [-1, 512, 7, 8]       2,359,296\n     BatchNorm2d-167            [-1, 512, 7, 8]           1,024\n            ReLU-168            [-1, 512, 7, 8]               0\n          Conv2d-169           [-1, 2048, 7, 8]       1,048,576\n     BatchNorm2d-170           [-1, 2048, 7, 8]           4,096\n            ReLU-171           [-1, 2048, 7, 8]               0\n      Bottleneck-172           [-1, 2048, 7, 8]               0\nAdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n          Linear-174                  [-1, 512]       1,049,088\n            ReLU-175                  [-1, 512]               0\n         Dropout-176                  [-1, 512]               0\n          Linear-177                  [-1, 128]          65,664\n            ReLU-178                  [-1, 128]               0\n         Dropout-179                  [-1, 128]               0\n          Linear-180                    [-1, 3]             387\n================================================================\nTotal params: 24,623,171\nTrainable params: 16,079,875\nNon-trainable params: 8,543,296\n----------------------------------------------------------------\nInput size (MB): 0.63\nForward/backward pass size (MB): 317.16\nParams size (MB): 93.93\nEstimated Total Size (MB): 411.72\n----------------------------------------------------------------\n","output_type":"stream"}],"execution_count":116},{"cell_type":"markdown","source":"#### Loss and Optimizer","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n# optimizer = optim.AdamW(model.parameters(), lr=1e-5, weight_decay=5e-4)\noptimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4, weight_decay=1e-4)\nscheduler = torch.optim.lr_scheduler.OneCycleLR(\n    optimizer,\n    max_lr=3e-4,\n    steps_per_epoch=len(train_loader),\n    epochs=num_epochs\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T12:49:06.372941Z","iopub.execute_input":"2025-10-17T12:49:06.373250Z","iopub.status.idle":"2025-10-17T12:49:06.379615Z","shell.execute_reply.started":"2025-10-17T12:49:06.373220Z","shell.execute_reply":"2025-10-17T12:49:06.378926Z"}},"outputs":[],"execution_count":117},{"cell_type":"code","source":"class EarlyStopping:\n    def __init__(self, patience=5, min_delta=0.0):\n        \"\"\"\n        Args:\n            patience (int): How many epochs to wait after last improvement.\n            min_delta (float): Minimum change to qualify as an improvement.\n        \"\"\"\n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.best_loss = None\n        self.early_stop = False\n\n    def __call__(self, val_loss):\n        if self.best_loss is None:\n            self.best_loss = val_loss\n        elif val_loss < self.best_loss - self.min_delta:\n            self.best_loss = val_loss\n            self.counter = 0\n        else:\n            self.counter += 1\n            if self.counter >= self.patience:\n                self.early_stop = True\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T12:49:06.380473Z","iopub.execute_input":"2025-10-17T12:49:06.380743Z","iopub.status.idle":"2025-10-17T12:49:06.395404Z","shell.execute_reply.started":"2025-10-17T12:49:06.380717Z","shell.execute_reply":"2025-10-17T12:49:06.394455Z"}},"outputs":[],"execution_count":118},{"cell_type":"markdown","source":"#### Training Loop","metadata":{}},{"cell_type":"code","source":"num_epochs = 30\nearly_stopping = EarlyStopping(patience=5, min_delta=0.001)\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    correct_train = 0\n    total_train = 0\n\n    # Wrap train_loader with tqdm\n    train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}] Training\")\n    \n    for images, labels in train_loader_tqdm:\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item() * images.size(0)\n        _, predicted = outputs.max(1)\n        total_train += labels.size(0)\n        correct_train += (predicted == labels).sum().item()\n\n        # Update tqdm bar postfix with running metrics\n        train_loader_tqdm.set_postfix({\n            'loss': f\"{loss.item():.4f}\"\n        })\n\n    train_loss = running_loss / total_train\n    train_acc = correct_train / total_train\n\n    # Validation\n    model.eval()\n    val_loss = 0.0\n    correct_val = 0\n    total_val = 0\n    val_loader_tqdm = tqdm(val_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}] Validation\")\n    \n    with torch.no_grad():\n        for images, labels in val_loader_tqdm:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item() * images.size(0)\n            _, predicted = outputs.max(1)\n            total_val += labels.size(0)\n            correct_val += (predicted == labels).sum().item()\n\n            val_loader_tqdm.set_postfix({\n                'loss': f\"{loss.item():.4f}\"\n            })\n\n    val_loss /= total_val\n    val_acc = correct_val / total_val\n\n    scheduler.step()\n    \n    # Final log for the epoch\n    print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} \"\n          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n\n    early_stopping(val_loss)\n    if early_stopping.early_stop:\n        print(f\"⏹ Early stopping triggered at epoch {epoch+1}\")\n        break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T12:49:06.396437Z","iopub.execute_input":"2025-10-17T12:49:06.396781Z","iopub.status.idle":"2025-10-17T12:56:03.413531Z","shell.execute_reply.started":"2025-10-17T12:49:06.396760Z","shell.execute_reply":"2025-10-17T12:56:03.412723Z"}},"outputs":[{"name":"stderr","text":"Epoch [1/30] Training: 100%|██████████| 66/66 [00:23<00:00,  2.75it/s, loss=0.8524]\nEpoch [1/30] Validation: 100%|██████████| 10/10 [00:02<00:00,  4.66it/s, loss=0.6913]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/30] Train Loss: 0.9966, Train Acc: 0.6943 Val Loss: 0.8067, Val Acc: 0.9733\n","output_type":"stream"},{"name":"stderr","text":"Epoch [2/30] Training: 100%|██████████| 66/66 [00:23<00:00,  2.76it/s, loss=0.5269]\nEpoch [2/30] Validation: 100%|██████████| 10/10 [00:02<00:00,  4.72it/s, loss=0.3666]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/30] Train Loss: 0.6762, Train Acc: 0.9505 Val Loss: 0.4362, Val Acc: 0.9900\n","output_type":"stream"},{"name":"stderr","text":"Epoch [3/30] Training: 100%|██████████| 66/66 [00:23<00:00,  2.75it/s, loss=0.3547]\nEpoch [3/30] Validation: 100%|██████████| 10/10 [00:02<00:00,  4.52it/s, loss=0.3008]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [3/30] Train Loss: 0.4347, Train Acc: 0.9767 Val Loss: 0.3390, Val Acc: 0.9833\n","output_type":"stream"},{"name":"stderr","text":"Epoch [4/30] Training: 100%|██████████| 66/66 [00:24<00:00,  2.74it/s, loss=0.3316]\nEpoch [4/30] Validation: 100%|██████████| 10/10 [00:02<00:00,  4.57it/s, loss=0.3040]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [4/30] Train Loss: 0.3645, Train Acc: 0.9824 Val Loss: 0.3286, Val Acc: 0.9900\n","output_type":"stream"},{"name":"stderr","text":"Epoch [5/30] Training: 100%|██████████| 66/66 [00:23<00:00,  2.77it/s, loss=0.4328]\nEpoch [5/30] Validation: 100%|██████████| 10/10 [00:02<00:00,  4.74it/s, loss=0.3064]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [5/30] Train Loss: 0.3426, Train Acc: 0.9848 Val Loss: 0.3249, Val Acc: 0.9900\n","output_type":"stream"},{"name":"stderr","text":"Epoch [6/30] Training: 100%|██████████| 66/66 [00:24<00:00,  2.74it/s, loss=0.3137]\nEpoch [6/30] Validation: 100%|██████████| 10/10 [00:02<00:00,  4.75it/s, loss=0.2984]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [6/30] Train Loss: 0.3400, Train Acc: 0.9890 Val Loss: 0.3221, Val Acc: 0.9933\n","output_type":"stream"},{"name":"stderr","text":"Epoch [7/30] Training: 100%|██████████| 66/66 [00:23<00:00,  2.81it/s, loss=0.3673]\nEpoch [7/30] Validation: 100%|██████████| 10/10 [00:02<00:00,  4.89it/s, loss=0.3004]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [7/30] Train Loss: 0.3370, Train Acc: 0.9910 Val Loss: 0.3196, Val Acc: 0.9900\n","output_type":"stream"},{"name":"stderr","text":"Epoch [8/30] Training: 100%|██████████| 66/66 [00:23<00:00,  2.80it/s, loss=0.3245]\nEpoch [8/30] Validation: 100%|██████████| 10/10 [00:02<00:00,  4.67it/s, loss=0.3055]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [8/30] Train Loss: 0.3296, Train Acc: 0.9938 Val Loss: 0.3226, Val Acc: 0.9933\n","output_type":"stream"},{"name":"stderr","text":"Epoch [9/30] Training: 100%|██████████| 66/66 [00:23<00:00,  2.79it/s, loss=0.4656]\nEpoch [9/30] Validation: 100%|██████████| 10/10 [00:02<00:00,  4.84it/s, loss=0.3038]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [9/30] Train Loss: 0.3353, Train Acc: 0.9886 Val Loss: 0.3198, Val Acc: 0.9900\n","output_type":"stream"},{"name":"stderr","text":"Epoch [10/30] Training: 100%|██████████| 66/66 [00:23<00:00,  2.81it/s, loss=0.3102]\nEpoch [10/30] Validation: 100%|██████████| 10/10 [00:02<00:00,  4.68it/s, loss=0.3011]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [10/30] Train Loss: 0.3261, Train Acc: 0.9952 Val Loss: 0.3170, Val Acc: 0.9933\n","output_type":"stream"},{"name":"stderr","text":"Epoch [11/30] Training: 100%|██████████| 66/66 [00:23<00:00,  2.77it/s, loss=0.3473]\nEpoch [11/30] Validation: 100%|██████████| 10/10 [00:02<00:00,  4.60it/s, loss=0.3015]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [11/30] Train Loss: 0.3228, Train Acc: 0.9943 Val Loss: 0.3150, Val Acc: 0.9900\n","output_type":"stream"},{"name":"stderr","text":"Epoch [12/30] Training: 100%|██████████| 66/66 [00:23<00:00,  2.80it/s, loss=0.3202]\nEpoch [12/30] Validation: 100%|██████████| 10/10 [00:02<00:00,  4.80it/s, loss=0.3010]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [12/30] Train Loss: 0.3228, Train Acc: 0.9976 Val Loss: 0.3198, Val Acc: 0.9900\n","output_type":"stream"},{"name":"stderr","text":"Epoch [13/30] Training: 100%|██████████| 66/66 [00:23<00:00,  2.82it/s, loss=0.3380]\nEpoch [13/30] Validation: 100%|██████████| 10/10 [00:02<00:00,  4.85it/s, loss=0.2976]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [13/30] Train Loss: 0.3224, Train Acc: 0.9957 Val Loss: 0.3183, Val Acc: 0.9867\n","output_type":"stream"},{"name":"stderr","text":"Epoch [14/30] Training: 100%|██████████| 66/66 [00:24<00:00,  2.75it/s, loss=0.3021]\nEpoch [14/30] Validation: 100%|██████████| 10/10 [00:02<00:00,  4.22it/s, loss=0.3021]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [14/30] Train Loss: 0.3209, Train Acc: 0.9962 Val Loss: 0.3182, Val Acc: 0.9867\n","output_type":"stream"},{"name":"stderr","text":"Epoch [15/30] Training: 100%|██████████| 66/66 [00:24<00:00,  2.68it/s, loss=0.3170]\nEpoch [15/30] Validation: 100%|██████████| 10/10 [00:02<00:00,  4.62it/s, loss=0.2974]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [15/30] Train Loss: 0.3169, Train Acc: 0.9990 Val Loss: 0.3163, Val Acc: 0.9867\n","output_type":"stream"},{"name":"stderr","text":"Epoch [16/30] Training: 100%|██████████| 66/66 [00:25<00:00,  2.63it/s, loss=0.3347]\nEpoch [16/30] Validation: 100%|██████████| 10/10 [00:02<00:00,  4.47it/s, loss=0.2969]","output_type":"stream"},{"name":"stdout","text":"Epoch [16/30] Train Loss: 0.3179, Train Acc: 0.9971 Val Loss: 0.3156, Val Acc: 0.9933\n⏹ Early stopping triggered at epoch 16\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":119},{"cell_type":"markdown","source":"#### Model Evaluation on Test data","metadata":{}},{"cell_type":"code","source":"# Test transform\n\ntest_data = ImageFolder('/kaggle/input/cat-dog-pandas/Cat-Dog_Pandas/Test',\n                       transform=test_transform)\ntest_loader =DataLoader(test_data, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T12:56:10.413162Z","iopub.execute_input":"2025-10-17T12:56:10.413904Z","iopub.status.idle":"2025-10-17T12:56:10.424996Z","shell.execute_reply.started":"2025-10-17T12:56:10.413880Z","shell.execute_reply":"2025-10-17T12:56:10.424214Z"}},"outputs":[],"execution_count":123},{"cell_type":"markdown","source":"#### Model testing with data","metadata":{}},{"cell_type":"code","source":"correct, total = 0, 0\nmodel.eval()\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, preds = outputs.max(1)\n        total += labels.size(0)\n        correct += (preds == labels).sum().item()\n\naccuracy = correct / total\nprint(f\"\\n✅ Overall Test Accuracy: {accuracy*100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T12:56:13.749373Z","iopub.execute_input":"2025-10-17T12:56:13.749653Z","iopub.status.idle":"2025-10-17T12:56:18.181910Z","shell.execute_reply.started":"2025-10-17T12:56:13.749632Z","shell.execute_reply":"2025-10-17T12:56:18.181123Z"}},"outputs":[{"name":"stdout","text":"\n✅ Overall Test Accuracy: 99.50%\n","output_type":"stream"}],"execution_count":124},{"cell_type":"code","source":"# Add this to the end of your training script\ntorch.save(model.state_dict(), 'model.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T12:57:09.218108Z","iopub.execute_input":"2025-10-17T12:57:09.218468Z","iopub.status.idle":"2025-10-17T12:57:09.506812Z","shell.execute_reply.started":"2025-10-17T12:57:09.218427Z","shell.execute_reply":"2025-10-17T12:57:09.505848Z"}},"outputs":[],"execution_count":126}]}