{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13216709,"sourceType":"datasetVersion","datasetId":8377230}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### Load all dependencies","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import transforms, datasets, models\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision.datasets import ImageFolder\nfrom PIL import Image\nfrom tqdm import tqdm    # for progress bar\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-01T16:32:34.149201Z","iopub.execute_input":"2025-10-01T16:32:34.149469Z","iopub.status.idle":"2025-10-01T16:32:41.141384Z","shell.execute_reply.started":"2025-10-01T16:32:34.149448Z","shell.execute_reply":"2025-10-01T16:32:41.140820Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"#### Set device","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T16:32:41.142381Z","iopub.execute_input":"2025-10-01T16:32:41.142833Z","iopub.status.idle":"2025-10-01T16:32:41.206289Z","shell.execute_reply.started":"2025-10-01T16:32:41.142804Z","shell.execute_reply":"2025-10-01T16:32:41.205362Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"#### Define Transform","metadata":{}},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Lambda(lambda img: img.convert('RGB')), # ensures RGB \n    transforms.Resize((224,224)),\n    # transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5] * 3, [0.5] * 3)\n])\n\ntest_transform = transforms.Compose([\n    transforms.Lambda(lambda img: img.convert('RGB')),\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5] * 3, [0.5] * 3)\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T16:32:41.207198Z","iopub.execute_input":"2025-10-01T16:32:41.207675Z","iopub.status.idle":"2025-10-01T16:32:41.235041Z","shell.execute_reply.started":"2025-10-01T16:32:41.207646Z","shell.execute_reply":"2025-10-01T16:32:41.234247Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"#### Load data","metadata":{}},{"cell_type":"code","source":"train_data = ImageFolder('/kaggle/input/cat-dot-pandas-dataset/Cat-Dog_Pandas/Train',\n                        transform = train_transform)\nval_data = ImageFolder('/kaggle/input/cat-dot-pandas-dataset/Cat-Dog_Pandas/Valid',\n                      transform = test_transform)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T16:32:41.236649Z","iopub.execute_input":"2025-10-01T16:32:41.236849Z","iopub.status.idle":"2025-10-01T16:32:44.029167Z","shell.execute_reply.started":"2025-10-01T16:32:41.236833Z","shell.execute_reply":"2025-10-01T16:32:44.028616Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class_names = train_data.classes   # different classes in our datasets\nclass_names","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T16:32:44.029823Z","iopub.execute_input":"2025-10-01T16:32:44.030071Z","iopub.status.idle":"2025-10-01T16:32:44.035131Z","shell.execute_reply.started":"2025-10-01T16:32:44.030049Z","shell.execute_reply":"2025-10-01T16:32:44.034355Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"['cat', 'dog', 'panda']"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"#### Data loader","metadata":{}},{"cell_type":"code","source":"train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T16:32:44.035909Z","iopub.execute_input":"2025-10-01T16:32:44.036110Z","iopub.status.idle":"2025-10-01T16:32:44.058452Z","shell.execute_reply.started":"2025-10-01T16:32:44.036093Z","shell.execute_reply":"2025-10-01T16:32:44.057924Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"dataiter = iter(train_loader)\nfeatures,label = next(dataiter)\nprint('number of data per batch: ',len(features))\nprint('number of label per batch: ',len(label))\nprint('labels : ',label)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T16:32:44.059348Z","iopub.execute_input":"2025-10-01T16:32:44.059710Z","iopub.status.idle":"2025-10-01T16:32:44.418873Z","shell.execute_reply.started":"2025-10-01T16:32:44.059687Z","shell.execute_reply":"2025-10-01T16:32:44.418199Z"}},"outputs":[{"name":"stdout","text":"number of data per batch:  32\nnumber of label per batch:  32\nlabels :  tensor([2, 0, 1, 2, 1, 2, 0, 2, 2, 1, 2, 1, 2, 0, 1, 0, 2, 0, 2, 1, 2, 2, 1, 0,\n        2, 0, 0, 0, 1, 0, 0, 2])\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"#### ResNet50 Tensfor Learning technique","metadata":{}},{"cell_type":"code","source":"model = models.resnet50(pretrained=True)\nnum_features = model.fc.in_features\nmodel.fc = nn.Linear(num_features, 3)  # 3 classes dog, cat, pandas\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T16:32:44.419601Z","iopub.execute_input":"2025-10-01T16:32:44.419876Z","iopub.status.idle":"2025-10-01T16:32:45.665846Z","shell.execute_reply.started":"2025-10-01T16:32:44.419851Z","shell.execute_reply":"2025-10-01T16:32:45.665273Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 206MB/s]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"#### Loss and Optimizer","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T16:32:45.666473Z","iopub.execute_input":"2025-10-01T16:32:45.666682Z","iopub.status.idle":"2025-10-01T16:32:45.671068Z","shell.execute_reply.started":"2025-10-01T16:32:45.666666Z","shell.execute_reply":"2025-10-01T16:32:45.670383Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"#### Training Loop","metadata":{}},{"cell_type":"code","source":"num_epochs = 15\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    correct_train = 0\n    total_train = 0\n\n    # Wrap train_loader with tqdm\n    train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}] Training\")\n    \n    for images, labels in train_loader_tqdm:\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item() * images.size(0)\n        _, predicted = outputs.max(1)\n        total_train += labels.size(0)\n        correct_train += (predicted == labels).sum().item()\n\n        # Update tqdm bar postfix with running metrics\n        train_loader_tqdm.set_postfix({\n            'loss': f\"{loss.item():.4f}\"\n        })\n\n    train_loss = running_loss / total_train\n    train_acc = correct_train / total_train\n\n    # Validation\n    model.eval()\n    val_loss = 0.0\n    correct_val = 0\n    total_val = 0\n    val_loader_tqdm = tqdm(val_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}] Validation\")\n    \n    with torch.no_grad():\n        for images, labels in val_loader_tqdm:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item() * images.size(0)\n            _, predicted = outputs.max(1)\n            total_val += labels.size(0)\n            correct_val += (predicted == labels).sum().item()\n\n            val_loader_tqdm.set_postfix({\n                'loss': f\"{loss.item():.4f}\"\n            })\n\n    val_loss /= total_val\n    val_acc = correct_val / total_val\n\n    # Final log for the epoch\n    print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} \"\n          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T16:32:45.672945Z","iopub.execute_input":"2025-10-01T16:32:45.673425Z","iopub.status.idle":"2025-10-01T16:38:29.672344Z","shell.execute_reply.started":"2025-10-01T16:32:45.673409Z","shell.execute_reply":"2025-10-01T16:38:29.671787Z"}},"outputs":[{"name":"stderr","text":"Epoch [1/15] Training: 100%|██████████| 66/66 [00:29<00:00,  2.25it/s, loss=0.3061]\nEpoch [1/15] Validation: 100%|██████████| 10/10 [00:03<00:00,  3.33it/s, loss=0.0047]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/15] Train Loss: 0.6632, Train Acc: 0.7429 Val Loss: 0.5666, Val Acc: 0.8067\n","output_type":"stream"},{"name":"stderr","text":"Epoch [2/15] Training: 100%|██████████| 66/66 [00:20<00:00,  3.24it/s, loss=0.4541]\nEpoch [2/15] Validation: 100%|██████████| 10/10 [00:01<00:00,  5.54it/s, loss=0.1739]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/15] Train Loss: 0.4220, Train Acc: 0.8362 Val Loss: 0.4145, Val Acc: 0.8233\n","output_type":"stream"},{"name":"stderr","text":"Epoch [3/15] Training: 100%|██████████| 66/66 [00:20<00:00,  3.23it/s, loss=0.1892]\nEpoch [3/15] Validation: 100%|██████████| 10/10 [00:01<00:00,  5.58it/s, loss=0.3323]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [3/15] Train Loss: 0.3064, Train Acc: 0.8843 Val Loss: 0.8027, Val Acc: 0.7633\n","output_type":"stream"},{"name":"stderr","text":"Epoch [4/15] Training: 100%|██████████| 66/66 [00:20<00:00,  3.24it/s, loss=0.1835]\nEpoch [4/15] Validation: 100%|██████████| 10/10 [00:01<00:00,  5.56it/s, loss=0.2976]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [4/15] Train Loss: 0.2600, Train Acc: 0.9143 Val Loss: 0.7185, Val Acc: 0.7533\n","output_type":"stream"},{"name":"stderr","text":"Epoch [5/15] Training: 100%|██████████| 66/66 [00:20<00:00,  3.22it/s, loss=0.2947]\nEpoch [5/15] Validation: 100%|██████████| 10/10 [00:01<00:00,  5.39it/s, loss=0.0110]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [5/15] Train Loss: 0.2216, Train Acc: 0.9167 Val Loss: 0.3624, Val Acc: 0.8667\n","output_type":"stream"},{"name":"stderr","text":"Epoch [6/15] Training: 100%|██████████| 66/66 [00:20<00:00,  3.18it/s, loss=0.0728]\nEpoch [6/15] Validation: 100%|██████████| 10/10 [00:01<00:00,  5.60it/s, loss=0.0000]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [6/15] Train Loss: 0.1725, Train Acc: 0.9357 Val Loss: 0.7809, Val Acc: 0.7900\n","output_type":"stream"},{"name":"stderr","text":"Epoch [7/15] Training: 100%|██████████| 66/66 [00:20<00:00,  3.24it/s, loss=0.1499]\nEpoch [7/15] Validation: 100%|██████████| 10/10 [00:01<00:00,  5.58it/s, loss=0.5314]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [7/15] Train Loss: 0.1387, Train Acc: 0.9524 Val Loss: 0.4571, Val Acc: 0.8700\n","output_type":"stream"},{"name":"stderr","text":"Epoch [8/15] Training: 100%|██████████| 66/66 [00:20<00:00,  3.21it/s, loss=0.4763]\nEpoch [8/15] Validation: 100%|██████████| 10/10 [00:01<00:00,  5.50it/s, loss=0.0001]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [8/15] Train Loss: 0.1273, Train Acc: 0.9552 Val Loss: 0.7573, Val Acc: 0.8467\n","output_type":"stream"},{"name":"stderr","text":"Epoch [9/15] Training: 100%|██████████| 66/66 [00:20<00:00,  3.24it/s, loss=0.0287]\nEpoch [9/15] Validation: 100%|██████████| 10/10 [00:01<00:00,  5.64it/s, loss=0.0447]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [9/15] Train Loss: 0.1561, Train Acc: 0.9457 Val Loss: 0.6131, Val Acc: 0.8500\n","output_type":"stream"},{"name":"stderr","text":"Epoch [10/15] Training: 100%|██████████| 66/66 [00:20<00:00,  3.23it/s, loss=0.0314]\nEpoch [10/15] Validation: 100%|██████████| 10/10 [00:01<00:00,  5.42it/s, loss=0.0000]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [10/15] Train Loss: 0.0909, Train Acc: 0.9652 Val Loss: 0.4976, Val Acc: 0.8800\n","output_type":"stream"},{"name":"stderr","text":"Epoch [11/15] Training: 100%|██████████| 66/66 [00:20<00:00,  3.24it/s, loss=0.0499]\nEpoch [11/15] Validation: 100%|██████████| 10/10 [00:01<00:00,  5.53it/s, loss=0.0001]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [11/15] Train Loss: 0.1323, Train Acc: 0.9529 Val Loss: 0.3493, Val Acc: 0.8867\n","output_type":"stream"},{"name":"stderr","text":"Epoch [12/15] Training: 100%|██████████| 66/66 [00:20<00:00,  3.24it/s, loss=0.0714]\nEpoch [12/15] Validation: 100%|██████████| 10/10 [00:01<00:00,  5.54it/s, loss=0.0002]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [12/15] Train Loss: 0.1263, Train Acc: 0.9557 Val Loss: 0.2797, Val Acc: 0.9200\n","output_type":"stream"},{"name":"stderr","text":"Epoch [13/15] Training: 100%|██████████| 66/66 [00:20<00:00,  3.21it/s, loss=0.0167]\nEpoch [13/15] Validation: 100%|██████████| 10/10 [00:01<00:00,  5.57it/s, loss=0.0001]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [13/15] Train Loss: 0.0713, Train Acc: 0.9762 Val Loss: 0.3322, Val Acc: 0.9133\n","output_type":"stream"},{"name":"stderr","text":"Epoch [14/15] Training: 100%|██████████| 66/66 [00:20<00:00,  3.24it/s, loss=0.0088]\nEpoch [14/15] Validation: 100%|██████████| 10/10 [00:01<00:00,  5.53it/s, loss=0.0005]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [14/15] Train Loss: 0.0429, Train Acc: 0.9876 Val Loss: 0.2686, Val Acc: 0.9167\n","output_type":"stream"},{"name":"stderr","text":"Epoch [15/15] Training: 100%|██████████| 66/66 [00:20<00:00,  3.22it/s, loss=0.2171]\nEpoch [15/15] Validation: 100%|██████████| 10/10 [00:01<00:00,  5.54it/s, loss=0.0000]","output_type":"stream"},{"name":"stdout","text":"Epoch [15/15] Train Loss: 0.0336, Train Acc: 0.9905 Val Loss: 0.6272, Val Acc: 0.8800\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"#### Model testing with unseen images","metadata":{}},{"cell_type":"code","source":"def RandomImagePrediction(filepath):\n    img_array = Image.open(filepath).convert(\"RGB\")\n    data_transforms=transforms.Compose([\n        transforms.Resize((224, 224)), \n        transforms.ToTensor(), \n        transforms.Normalize([0.5]*3, [0.5]*3)\n    ])\n    img = data_transforms(img_array).unsqueeze(dim=0) # Returns a new tensor with a dimension of size one inserted at the specified position.\n    load = DataLoader(img)\n    \n    for x in load:\n        x=x.to(device)\n        pred = model(x)\n        _, preds = torch.max(pred, 1)\n        print(f\"class : {preds}\")\n\n        \n        if preds[0] == 0: print(f\"predicted ----> Cat\")\n        \n        elif preds[0] == 1: print(f\"predicted ----> Dog\")\n\n        else : print(f'predicted ---> Pandas')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T16:38:29.673001Z","iopub.execute_input":"2025-10-01T16:38:29.673185Z","iopub.status.idle":"2025-10-01T16:38:29.678490Z","shell.execute_reply.started":"2025-10-01T16:38:29.673170Z","shell.execute_reply":"2025-10-01T16:38:29.677765Z"},"_kg_hide-input":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    RandomImagePrediction(\"/kaggle/input/cat-dot-pandas-dataset/Cat-Dog_Pandas/Test/104000.jpg\") # cat image\n    RandomImagePrediction(\"/kaggle/input/cat-dot-pandas-dataset/Cat-Dog_Pandas/Test/133600.jpg\") # dog image\n    RandomImagePrediction(\"/kaggle/input/cat-dot-pandas-dataset/Cat-Dog_Pandas/Test/149900.jpg\") # panda image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T16:38:29.679126Z","iopub.execute_input":"2025-10-01T16:38:29.679362Z","iopub.status.idle":"2025-10-01T16:38:29.809268Z","shell.execute_reply.started":"2025-10-01T16:38:29.679338Z","shell.execute_reply":"2025-10-01T16:38:29.808482Z"}},"outputs":[{"name":"stdout","text":"class : tensor([0], device='cuda:0')\npredicted ----> Cat\nclass : tensor([1], device='cuda:0')\npredicted ----> Dog\nclass : tensor([2], device='cuda:0')\npredicted ---> Pandas\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"#### Save Trained Model","metadata":{}},{"cell_type":"code","source":"torch.save(model.state_dict(), \"resnet50_cat_dog_panda.pth\")\nprint(\"Model saved as resnet50_cat_dog_panda.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T16:47:01.385700Z","iopub.execute_input":"2025-10-01T16:47:01.385983Z","iopub.status.idle":"2025-10-01T16:47:01.532126Z","shell.execute_reply.started":"2025-10-01T16:47:01.385964Z","shell.execute_reply":"2025-10-01T16:47:01.531391Z"}},"outputs":[{"name":"stdout","text":"Model saved as resnet50_cat_dog_panda.pth\n","output_type":"stream"}],"execution_count":13}]}